{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ## Objective\n",
    "    \n",
    "            Investigate the trend of food poisoning incidents caused by New York City restaurants from 2010 to current.\n",
    "     \n",
    "    ## Source Data\n",
    "    \n",
    "      NYC Heath inspection data-https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/43nn-pn8j\n",
    "       \n",
    "      NYC food poisoning complaints - https://data.cityofnewyork.us/resource/gjkf-etq5.json\n",
    "\n",
    "        \n",
    "    ## Process    \n",
    "    \n",
    "        1. Extract data from websites\n",
    "        2. Transform data\n",
    "        3. Load data   \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Install and import neccessary libraries and functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sodapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Requests made without an app_token will be subject to strict throttling limits.\n"
     ]
    }
   ],
   "source": [
    "client = Socrata(\"data.cityofnewyork.us\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    " ### Extract Jason files from predefined datasets  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Extract First 400000 Health inspection results in JSON formant from API to Python list of dict by sodapy\n",
    "\n",
    "inspections = client.get(\"9w7m-hzhe\", limit=400000)            \n",
    "    \n",
    "            # Extract First 30000 records of reported food poisoning incidents\n",
    "            # results in JSON formant from API to Python list of dict by sodapy\n",
    "        \n",
    "food_df = client.get(\"gjkf-etq5\", limit=30000)                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Tranform Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    To make this data useful we need to connect the health inspection data to the food poisoning incident data thru a \n",
    "    common \"Key\". We choose to use a combination of the Borough name and Street address (In New York City the five boroughs making up the city have duplicate street names and numbers - adding the borough to the street address makes the \"key\" unique.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Convert to pandas DataFrame\n",
    "\n",
    "inspections_df = pd.DataFrame.from_records(inspections)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Rename columns       \n",
    "\n",
    "inspections = inspections_df.rename(columns={\"action\": \"Action\",\"boro\": \"Borough\",\"building\": \"Street_Number\",\n",
    "                                          \"camis\": \"Restaurant_ID\",\"critical_flag\": \"Critical_Flag\",\n",
    "                                          \"cuisine_description\": \"Cuisine\",\"dba\": \"Name\",\"grade\": \"Grade\",\n",
    "                                          \"inspection_date\": \"Inspection_Date\",\"inspection_type\": \"Inspection_Type\",\n",
    "                                          \"score\": \"Score\",\"street\": \"Street\",\"violation_code\": \"Violation_Code\",\n",
    "                                          \"violation_description\": \"Violation_Description\",\"zipcode\": \"Zip\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Make copy of Street andress before manipulating\n",
    "\n",
    "inspections['Orig_Street'] = inspections['Street']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Convert inspection Date to datetime fomat\n",
    "    \n",
    "inspections['Inspection_Date'] = pd.to_datetime(inspections[\"Inspection_Date\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            The inspection data set used a \"-\" inconsistently in the \"Street Number\" of the address.\n",
    "            We decided to remove it all together from both data sets to be consistant\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Remove \"-\" from the Street Number\n",
    " \n",
    "                # split the \"street number into columns at the \"-\"    \n",
    "                \n",
    "x = inspections['Street_Number'].str.split('-', expand=True).rename(columns = lambda x: \"string\"+str(x+1))\n",
    "\n",
    "                # define 3 new created columns as strings in order to replace \"None\" with a \" \"\n",
    "\n",
    "x['string1'] = x['string1'].astype(str)\n",
    "x['string2'] = x['string2'].astype(str)\n",
    "x['string3'] = x['string3'].astype(str)\n",
    "\n",
    "j = x.replace(['None'],[' '])\n",
    "\n",
    "                # concatenate columns back to one 'street number without th \"-\"\n",
    "\n",
    "j['Street_Number'] = j['string1'] + j['string2'] +j['string3']\n",
    "\n",
    "                # strip any trailing blank spaces from column        \n",
    "\n",
    "j = j.applymap(lambda x: x.strip() if type(x)==str else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "          # Remove double \"white spaces from 'Street Name'  \n",
    "\n",
    "\n",
    "inspections['Street'] = inspections.Street.astype(str)         # Define Street as a string in order to split/join\n",
    "\n",
    "street = inspections['Street']                                 # Define variables for loop    \n",
    "x = []                                                         \n",
    "\n",
    "for i in street:                                               # Take out double white spaces\n",
    "        x.append(' '.join(i.split()))                            \n",
    "    \n",
    "y = pd.Series(x)                                               # Add new 'Adjusted Street' column to df\n",
    "inspections.insert(loc=0, column='Adj_Street', value=y)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # The Street names from both data sets were inconsistent:\n",
    "        # with regard to :\n",
    "            \n",
    "                # the spelling of thorough-fare names,\n",
    "                # representation of number named streets\n",
    "                # directional notation\n",
    "                \n",
    "        # we first split the Address into columns with \"split - expand\" \n",
    "        # then replaced all \"found unique versions\" with consistent names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Split 'Street address into colums'\n",
    "                \n",
    "x = inspections['Adj_Street'].str.split(' ', expand=True).rename(columns = lambda x: \"string\"+str(x+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Replace thorough-fare names\n",
    "\n",
    "y = x.replace([\"AIR\",\"AIRPOR\",\"AIRPORT\",\"AIRPOT\",\"airport\",\"ARPT\",\"Airport\",\"AMERICAS\",\"AV\",\"AVE\",\"AVE.\",\"AVENUE\",\"AVEUE\",\n",
    "         \"Ave\",\"Ave\",\"Avenue\",\"ave\",\"avenue\",\"BLVD\",\"BLVD.\",\"BOULEVA\",\"BOULEVARD\",\"Blvd\",\"BROADFWAY\",\"BROADWAY\",\n",
    "         \"Broadwaty\",\"Broadway\",\"BL\",\"BLDG\",\"BUIL\",\"BUILDING\",\"CENTER\",\"CTR\",\"Center\",\"CIR\",\"CIRCLE\",\"CONCOURS\",\n",
    "         \"CONCOURSE\",\"CONCRS\",\"COURT\",\"CT\",\"DR\",\"DRIVE\",\"EXPRESSWAY\",\"EXPWY\",\"EXPY\",\"EXT\",\"EXTENSION\",\"HIGHWAY\",\n",
    "         \"HWY\",\"IS\",\"ISLAND\",\"LANE\",\"LN\",\"PARK\",\"PK\",\"PARKWA\",\"PARKWAY\",\"PKWY\",\"PLC\",\"PL\",\"PLACE\",\"PLAZA\",\"PLZ\",\n",
    "         \"Plaza\",\"RD\",\"ROAD\",\"SQ\",\"SQUARE\",\"SREET\",\"ST\",\"ST.\",\"STEET\",\"STREET\",\"STREET.\",\"STRRET\",\"STTREET\",\"St\",\n",
    "         \"Street\",\"st\",\"street]\",\"TNPK\",\"TPKE\",\"TURNPIKE\",\"TER\",\"TERRACE\",\"TERM\",\"TERMINAL\"],\n",
    "              [\"AIRPORT\",\"AIRPORT\",\n",
    "         \"AIRPORT\",\"AIRPORT\",\"AIRPORT\",\"AIRPORT\",\"AIRPORT\",\"AMERICAS\",\"AVENUE\",\"AVENUE\",\"AVENUE\",\n",
    "         \"AVENUE\",\"AVENUE\",\"AVENUE\",\"AVENUE\",\"AVENUE\",\"AVENUE\",\"AVENUE\",\"BOULEVARD\",\"BOULEVARD\",\"BOULEVARD\",\n",
    "         \"BOULEVARD\",\"BOULEVARD\",\"BROADWAY\",\"BROADWAY\",\"BROADWAY\",\"BROADWAY\",\"BUILDING\",\"BUILDING\",\"BUILDING\",\n",
    "         \"BUILDING\",\"CENTER\",\"CENTER\",\"CENTER\",\"CIRCLE\",\"CIRCLE\",\"CONCOURSE\",\"CONCOURSE\",\"CONCOURSE\",\"COURT\",\n",
    "         \"COURT\",\"DRIVE\",\"DRIVE\",\"EXPRESSWAY\",\"EXPRESSWAY\",\"EXPRESSWAY\",\"EXTENSION\",\"EXTENSION\",\"HIGHWAY\",\n",
    "         \"HIGHWAY\",\"ISLAND\",\"ISLAND\",\"LANE\",\"LANE\",\"PARK\",\"PARK\",\"PARKWAY\",\"PARKWAY\",\"PARKWAY\",\"PLACE\",\"PLACE\",\n",
    "         \"PLACE\",\"PLAZA\",\"PLAZA\",\"PLAZA\",\"ROAD\",\"ROAD\",\"SQUARE\",\"SQUARE\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\n",
    "         \"STREET\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\"TURNPIKE\",\"TURNPIKE\",\"TURNPIKE\",\n",
    "         \"TERRACE\",\"TERRACE\",\"TERMINAL\",\"TERMINAL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Replace numbered named streets\n",
    "\n",
    "z = y.replace([\"1ST\",\"2ND\",\"3RD\",\"4TH\",\"5TH\",\"6TH\",\"7TH\",\"8TH\",\"9TH\",\"10TH\",\"11TH\",\"12TH\",\"13TH\",\"14TH\",\"15TH\",\"16TH\",\n",
    "               \"17TH\",\"18TH\",\"19TH\",\"20TH\",\"21ST\",\"22ND\",\"23RD\",\"24TH\",\"25TH\",\"26TH\",\"27TH\",\"28TH\",\"29TH\",\"30TH\",\"31ST\",\n",
    "               \"32ND\",\"33RD\",\"34TH\",\"35TH\",\"36TH\",\"37TH\",\"38TH\",\"39TH\",\"40TH\",\"41ST\",\"42ND\",\"43RD\",\"44TH\",\"45TH\",\"46TH\",\n",
    "               \"47TH\",\"48TH\",\"49TH\",\"50TH\",\"51ST\",\"52ND\",\"53RD\",\"54TH\",\"55TH\",\"56TH\",\"57TH\",\"58TH\",\"59TH\",\"60TH\",\"61ST\",\n",
    "               \"62ND\",\"63RD\",\"64TH\",\"65TH\",\"66TH\",\"67TH\",\"68TH\",\"69TH\",\"70TH\",\"71ST\",\"72ND\",\"73RD\",\"74TH\",\"75TH\",\"76TH\",\n",
    "               \"77TH\",\"78TH\",\"79TH\",\"80TH\",\"81ST\",\"82ND\",\"83RD\",\"84TH\",\"85TH\",\"86TH\",\"87TH\",\"88TH\",\"89TH\",\"90TH\",\"91ST\",\n",
    "               \"92ND\",\"93RD\",\"94TH\",\"95TH\",\"96TH\",\"97TH\",\"98TH\",\"99TH\",\"100TH\",\"101ST\",\"102ND\",\"103RD\",\"104TH\",\"105TH\",\n",
    "               \"106TH\",\"107TH\",\"108TH\",\"109TH\",\"110TH\",\"111TH\",\"112TH\",\"113TH\",\"114TH\",\"115TH\",\"116TH\",\"117TH\",\"118TH\",\n",
    "               \"119TH\",\"120TH\",\"121ST\",\"122ND\",\"123RD\",\"124TH\",\"125TH\",\"126TH\",\"127TH\",\"128TH\",\"129TH\",\"130TH\",\"131ST\",\n",
    "               \"132ND\",\"133RD\",\"134TH\",\"135TH\",\"136TH\",\"137TH\",\"138TH\",\"139TH\",\"140TH\",\"141ST\",\"142ND\",\"143RD\",\"144TH\",\n",
    "               \"145TH\",\"146TH\",\"147TH\",\"148TH\",\"149TH\",\"150TH\",\"151ST\",\"152ND\",\"153RD\",\"154TH\",\"155TH\",\"156TH\",\"157TH\",\n",
    "               \"158TH\",\"159TH\",\"160TH\",\"161ST\",\"162ND\",\"163RD\",\"164TH\",\"165TH\",\"166TH\",\"167TH\",\"168TH\",\"169TH\",\"170TH\",\n",
    "               \"171ST\",\"172ND\",\"173RD\",\"174TH\",\"175TH\",\"176TH\",\"177TH\",\"178TH\",\"179TH\",\"180TH\",\"181ST\",\"182ND\",\"183RD\",\n",
    "               \"184TH\",\"185TH\",\"186TH\",\"187TH\",\"188TH\",\"189TH\",\"190TH\",\"191ST\",\"192ND\",\"193RD\",\"194TH\",\"195TH\",\"196TH\",\n",
    "               \"197TH\",\"198TH\",\"199TH\",\"200TH\",\"201ST\",\"202ND\",\"203RD\",\"204TH\",\"205TH\",\"206TH\",\"207TH\",\"208TH\",\"209TH\",\n",
    "               \"210TH\",\"211TH\",\"212TH\",\"213TH\",\"214TH\",\"215TH\",\"216TH\",\"217TH\",\"218TH\",\"219TH\",\"220TH\",\"221ST\",\"222ND\",\n",
    "               \"223RD\",\"224TH\",\"225TH\",\"226TH\",\"227TH\",\"228TH\",\"229TH\",\"230TH\",\"231ST\",\"232ND\",\"233RD\",\"234TH\",\"235TH\",\n",
    "               \"236TH\",\"237TH\",\"238TH\",\"239TH\",\"240TH\",\"241ST\",\"242ND\",\"243RD\",\"244TH\",\"245TH\",\"246TH\",\"247TH\",\"248TH\",\n",
    "               \"249TH\",\"250TH\",\"251ST\",\"252ND\",\"253RD\",\"254TH\",\"255TH\",\"256TH\",\"257TH\",\"258TH\",\"259TH\",\"260TH\",\"261ST\",\n",
    "               \"262ND\",\"263RD\",\"264TH\",\"265TH\",\"266TH\",\"267TH\",\"268TH\",\"269TH\",\"270TH\",\"271ST\",\"272ND\",\"273RD\",\"274TH\",\n",
    "               \"275TH\",\"276TH\",\"277TH\",\"278TH\",\"279TH\",\"280TH\",\"281ST\",\"282ND\",\"283RD\",\"284TH\",\"285TH\",\"286TH\",\"287TH\",\n",
    "               \"288TH\",\"289TH\",\"290TH\",\"291ST\",\"292ND\",\"293RD\",\"294TH\",\"295TH\",\"296TH\",\"297TH\",\"298TH\",\"299TH\",\"300TH\"],\n",
    "               [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,\n",
    "                39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,\n",
    "                74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,\n",
    "                107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,\n",
    "                133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,\n",
    "                159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,\n",
    "                185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,\n",
    "                211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,\n",
    "                237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,\n",
    "                263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,\n",
    "                289,290,291,292,293,294,295,296,297,298,299,300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Replaced directional notation\n",
    "\n",
    "a = z.replace([\"N\",\"N.\",\"Nr\",\"Nr.\",\"Nth\",\"Nth.\",\"Nrth\",\"Nrth.\",\"S\",\"S.\",\"Sth\",\"Sth.\",\"E\",\"E.\",\"Est\",\n",
    "               \"Est.\",\"W\",\"W.\",\"Wst\",\"Wst.\"],[\"NORTH\",\"NORTH\",\"NORTH\",\"NORTH\",\"NORTH\",\"NORTH\",\"NORTH\",\n",
    "               \"NORTH\",\"SOUTH\",\"SOUTH\",\"SOUTH\",\"SOUTH\",\"EAST\",\"EAST\",\"EAST\",\"EAST\",\"WEST\",\"WEST\",\"WEST\",\"WEST\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Converted columns to strings inorder to replace \"None\" with \" \"\n",
    "\n",
    "a['string1']= a['string1'].astype(str)\n",
    "a['string2']= a['string2'].astype(str)\n",
    "a['string3']= a['string3'].astype(str)\n",
    "a['string4']= a['string4'].astype(str)\n",
    "a['string5']= a['string5'].astype(str)\n",
    "a['string6']= a['string6'].astype(str)\n",
    "\n",
    "p = a.replace(['None'],[' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "                # Concatenated split columns back to full street address\n",
    "\n",
    "p['Adj_New'] = j['Street_Number']+' '+p['string1']+' '+p['string2']+' '+p['string3']+' '+p['string4']+' '+p['string5']+' '+p['string6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Add 'Final Street' column to inspection df\n",
    "\n",
    "inspections['Final_Street'] = p['Adj_New']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # concatenate 'Final Street' with 'Borough' to create unique key to join tables\n",
    " \n",
    "inspections['Address_ID'] = inspections['Borough'] + \" | \" + inspections['Final_Street']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Reoder the columns\n",
    "\n",
    "inspections = inspections[[\"Restaurant_ID\",\"Address_ID\",\"Inspection_Date\",\"Name\",\n",
    "                           \"Cuisine\",\"Final_Street\",\"Borough\",\"Zip\",\"Score\",\n",
    "                           \"Violation_Code\",\"Violation_Description\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "                # Trim white space \n",
    "\n",
    "inspections = inspections.applymap(lambda x: x.strip() if type(x)==str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Drop 'N/A' rows       \n",
    "\n",
    "inspections = inspections[inspections.Zip != 'N/A']\n",
    "inspections = inspections[inspections.Name != 'N/A']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Replace blanks with 'nan'\n",
    "\n",
    "inspections['Score'].replace('', np.nan, inplace=True)\n",
    "inspections['Violation_Description'].replace('', np.nan, inplace=True)  \n",
    "\n",
    "                 # Drop 'N/A' rows \n",
    "    \n",
    "inspections.dropna(subset=['Violation_Description'], inplace=True)        \n",
    "inspections.dropna(subset=['Score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Set 'Restaurant_ID' as index\n",
    "\n",
    "inspections.set_index('Restaurant_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Save Transforme DataFrame to csv file\n",
    "\n",
    "inspections.to_csv('c:/LearnPython/final_inspections.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    (perform same tranformation as above to food dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Convert to pandas DataFrame\n",
    "\n",
    "food_df = pd.DataFrame.from_records(food_df)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Rename columns       \n",
    "        \n",
    "food = food_df.rename(columns={\"created_date\": \"Incident_Date\",\"complaint_type\": \"Complaint\",\"address_type\": \"Address_Type\",\n",
    "                               \"incident_address\": \"Street_Address\",\"street_name\": \"Street\",\"borough\": \"Borough\",\n",
    "                               \"city\": \"City\",\"incident_zip\": \"Zip\",\"descriptor\": \"Descriptor\",\"unique_key\":\"id\",\n",
    "                                \"longitude\": \"Longitude\", \"latitude\":\"Latitude\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                # Transform 'Incident Date' to date format and remove time portion\n",
    "    \n",
    "\n",
    "food['Incident_Date'] = pd.to_datetime(food[\"Incident_Date\"])\n",
    "\n",
    "food['Incident_Date']= food['Incident_Date'].astype(str)\n",
    "x = food['Incident_Date'].str.split(' ', expand=True).rename(columns = lambda x: \"string\"+str(x+1))\n",
    "x['string1'] = pd.to_datetime(x['string1'])\n",
    "\n",
    "food['Incident_Date'] = x['string1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Save 'Origina Street' name for comparison                    \n",
    "\n",
    "food['Orig_Street'] = food['Street_Address']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Remove white space  \n",
    "    \n",
    "food['Street_Address'] = food.Street_Address.astype(str)       # Define Street as a string in order to split/join\n",
    "\n",
    "y = food['Street_Address']                                     # Define variables for loop    \n",
    "x = []                                                         \n",
    "\n",
    "for i in y:                                                    # Take out double white spaces\n",
    "        x.append(' '.join(i.split()))                             \n",
    "    \n",
    "y = pd.Series(x)                                               # Add new 'Adjusted Street' column to df\n",
    "food.insert(loc=0, column='Adj_Street', value=y)                 \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Expand columns inorder to replace inconsistent names with consistent\n",
    "\n",
    "x = food['Adj_Street'].str.split(' ', expand=True).rename(columns = lambda x: \"string\"+str(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Replace thorough-fare names\n",
    "\n",
    "y = x.replace([\"AIR\",\"AIRPOR\",\"AIRPORT\",\"AIRPOT\",\"airport\",\"ARPT\",\"Airport\",\"AMERICAS\",\"AV\",\"AVE\",\"AVE.\",\"AVENUE\",\n",
    "               \"AVEUE\",\"Ave\",\"Ave\",\"Avenue\",\"ave\",\"avenue\",\"BLVD\",\"BLVD.\",\"BOULEVA\",\"BOULEVARD\",\"Blvd\",\"BROADFWAY\",\n",
    "               \"BROADWAY\",\"Broadwaty\",\"Broadway\",\"BL\",\"BLDG\",\"BUIL\",\"BUILDING\",\"CENTER\",\"CTR\",\"Center\",\"CIR\",\"CIRCLE\",\n",
    "               \"CONCOURS\",\"CONCOURSE\",\"CONCRS\",\"COURT\",\"CT\",\"DR\",\"DRIVE\",\"EXPRESSWAY\",\"EXPWY\",\"EXPY\",\"EXT\",\"EXTENSION\",\n",
    "               \"HIGHWAY\",\"HWY\",\"IS\",\"ISLAND\",\"LANE\",\"LN\",\"PARK\",\"PK\",\"PARKWA\",\"PARKWAY\",\"PKWY\",\"PLC\",\"PL\",\"PLACE\",\n",
    "               \"PLAZA\",\"PLZ\",\"Plaza\",\"RD\",\"ROAD\",\"SQ\",\"SQUARE\",\"SREET\",\"ST\",\"ST.\",\"STEET\",\"STREET\",\"STREET.\",\"STRRET\",\n",
    "               \"STTREET\",\"St\",\"Street\",\"st\",\"street]\",\"TNPK\",\"TPKE\",\"TURNPIKE\",\"TER\",\"TERRACE\",\"TERM\",\"TERMINAL\"],\n",
    "               [\"AIRPORT\",\"AIRPORT\",\"AIRPORT\",\"AIRPORT\",\"AIRPORT\",\"AIRPORT\",\"AIRPORT\",\"AMERICAS\",\"AVENUE\",\"AVENUE\",\n",
    "                \"AVENUE\",\"AVENUE\",\"AVENUE\",\"AVENUE\",\"AVENUE\",\"AVENUE\",\"AVENUE\",\"AVENUE\",\"BOULEVARD\",\"BOULEVARD\",\n",
    "                \"BOULEVARD\",\"BOULEVARD\",\"BOULEVARD\",\"BROADWAY\",\"BROADWAY\",\"BROADWAY\",\"BROADWAY\",\"BUILDING\",\"BUILDING\",\n",
    "                \"BUILDING\",\"BUILDING\",\"CENTER\",\"CENTER\",\"CENTER\",\"CIRCLE\",\"CIRCLE\",\"CONCOURSE\",\"CONCOURSE\",\"CONCOURSE\",\n",
    "                \"COURT\",\"COURT\",\"DRIVE\",\"DRIVE\",\"EXPRESSWAY\",\"EXPRESSWAY\",\"EXPRESSWAY\",\"EXTENSION\",\"EXTENSION\",\n",
    "                \"HIGHWAY\",\"HIGHWAY\",\"ISLAND\",\"ISLAND\",\"LANE\",\"LANE\",\"PARK\",\"PARK\",\"PARKWAY\",\"PARKWAY\",\"PARKWAY\",\n",
    "                \"PLACE\",\"PLACE\",\"PLACE\",\"PLAZA\",\"PLAZA\",\"PLAZA\",\"ROAD\",\"ROAD\",\"SQUARE\",\"SQUARE\",\"STREET\",\"STREET\",\n",
    "                \"STREET\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\"STREET\",\"TURNPIKE\",\n",
    "                \"TURNPIKE\",\"TURNPIKE\",\"TERRACE\",\"TERRACE\",\"TERMINAL\",\"TERMINAL\"])\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Replace numbered named streets\n",
    "\n",
    "q = y.replace([\"1ST\",\"2ND\",\"3RD\",\"4TH\",\"5TH\",\"6TH\",\"7TH\",\"8TH\",\"9TH\",\"10TH\",\"11TH\",\"12TH\",\"13TH\",\"14TH\",\"15TH\",\"16TH\",\n",
    "               \"17TH\",\"18TH\",\"19TH\",\"20TH\",\"21ST\",\"22ND\",\"23RD\",\"24TH\",\"25TH\",\"26TH\",\"27TH\",\"28TH\",\"29TH\",\"30TH\",\"31ST\",\n",
    "               \"32ND\",\"33RD\",\"34TH\",\"35TH\",\"36TH\",\"37TH\",\"38TH\",\"39TH\",\"40TH\",\"41ST\",\"42ND\",\"43RD\",\"44TH\",\"45TH\",\"46TH\",\n",
    "               \"47TH\",\"48TH\",\"49TH\",\"50TH\",\"51ST\",\"52ND\",\"53RD\",\"54TH\",\"55TH\",\"56TH\",\"57TH\",\"58TH\",\"59TH\",\"60TH\",\"61ST\",\n",
    "               \"62ND\",\"63RD\",\"64TH\",\"65TH\",\"66TH\",\"67TH\",\"68TH\",\"69TH\",\"70TH\",\"71ST\",\"72ND\",\"73RD\",\"74TH\",\"75TH\",\"76TH\",\n",
    "               \"77TH\",\"78TH\",\"79TH\",\"80TH\",\"81ST\",\"82ND\",\"83RD\",\"84TH\",\"85TH\",\"86TH\",\"87TH\",\"88TH\",\"89TH\",\"90TH\",\"91ST\",\n",
    "               \"92ND\",\"93RD\",\"94TH\",\"95TH\",\"96TH\",\"97TH\",\"98TH\",\"99TH\",\"100TH\",\"101ST\",\"102ND\",\"103RD\",\"104TH\",\"105TH\",\n",
    "               \"106TH\",\"107TH\",\"108TH\",\"109TH\",\"110TH\",\"111TH\",\"112TH\",\"113TH\",\"114TH\",\"115TH\",\"116TH\",\"117TH\",\"118TH\",\n",
    "               \"119TH\",\"120TH\",\"121ST\",\"122ND\",\"123RD\",\"124TH\",\"125TH\",\"126TH\",\"127TH\",\"128TH\",\"129TH\",\"130TH\",\"131ST\",\n",
    "               \"132ND\",\"133RD\",\"134TH\",\"135TH\",\"136TH\",\"137TH\",\"138TH\",\"139TH\",\"140TH\",\"141ST\",\"142ND\",\"143RD\",\"144TH\",\n",
    "               \"145TH\",\"146TH\",\"147TH\",\"148TH\",\"149TH\",\"150TH\",\"151ST\",\"152ND\",\"153RD\",\"154TH\",\"155TH\",\"156TH\",\"157TH\",\n",
    "               \"158TH\",\"159TH\",\"160TH\",\"161ST\",\"162ND\",\"163RD\",\"164TH\",\"165TH\",\"166TH\",\"167TH\",\"168TH\",\"169TH\",\"170TH\",\n",
    "               \"171ST\",\"172ND\",\"173RD\",\"174TH\",\"175TH\",\"176TH\",\"177TH\",\"178TH\",\"179TH\",\"180TH\",\"181ST\",\"182ND\",\"183RD\",\n",
    "               \"184TH\",\"185TH\",\"186TH\",\"187TH\",\"188TH\",\"189TH\",\"190TH\",\"191ST\",\"192ND\",\"193RD\",\"194TH\",\"195TH\",\"196TH\",\n",
    "               \"197TH\",\"198TH\",\"199TH\",\"200TH\",\"201ST\",\"202ND\",\"203RD\",\"204TH\",\"205TH\",\"206TH\",\"207TH\",\"208TH\",\"209TH\",\n",
    "               \"210TH\",\"211TH\",\"212TH\",\"213TH\",\"214TH\",\"215TH\",\"216TH\",\"217TH\",\"218TH\",\"219TH\",\"220TH\",\"221ST\",\"222ND\",\n",
    "               \"223RD\",\"224TH\",\"225TH\",\"226TH\",\"227TH\",\"228TH\",\"229TH\",\"230TH\",\"231ST\",\"232ND\",\"233RD\",\"234TH\",\"235TH\",\n",
    "               \"236TH\",\"237TH\",\"238TH\",\"239TH\",\"240TH\",\"241ST\",\"242ND\",\"243RD\",\"244TH\",\"245TH\",\"246TH\",\"247TH\",\"248TH\",\n",
    "               \"249TH\",\"250TH\",\"251ST\",\"252ND\",\"253RD\",\"254TH\",\"255TH\",\"256TH\",\"257TH\",\"258TH\",\"259TH\",\"260TH\",\"261ST\",\n",
    "               \"262ND\",\"263RD\",\"264TH\",\"265TH\",\"266TH\",\"267TH\",\"268TH\",\"269TH\",\"270TH\",\"271ST\",\"272ND\",\"273RD\",\"274TH\",\n",
    "               \"275TH\",\"276TH\",\"277TH\",\"278TH\",\"279TH\",\"280TH\",\"281ST\",\"282ND\",\"283RD\",\"284TH\",\"285TH\",\"286TH\",\"287TH\",\n",
    "               \"288TH\",\"289TH\",\"290TH\",\"291ST\",\"292ND\",\"293RD\",\"294TH\",\"295TH\",\"296TH\",\"297TH\",\"298TH\",\"299TH\",\"300TH\"],\n",
    "               [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,\n",
    "                39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,\n",
    "                74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,\n",
    "                107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,\n",
    "                133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,\n",
    "                159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,\n",
    "                185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,\n",
    "                211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,\n",
    "                237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,\n",
    "                263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,\n",
    "                289,290,291,292,293,294,295,296,297,298,299,300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "              # Replaced directional notation\n",
    "\n",
    "a = q.replace([\"N\",\"N.\",\"Nr\",\"Nr.\",\"Nth\",\"Nth.\",\"Nrth\",\"Nrth.\",\"S\",\"S.\",\"Sth\",\"Sth.\",\"E\",\"E.\",\"Est\",\n",
    "               \"Est.\",\"W\",\"W.\",\"Wst\",\"Wst.\"],[\"NORTH\",\"NORTH\",\"NORTH\",\"NORTH\",\"NORTH\",\"NORTH\",\"NORTH\",\n",
    "               \"NORTH\",\"SOUTH\",\"SOUTH\",\"SOUTH\",\"SOUTH\",\"EAST\",\"EAST\",\"EAST\",\"EAST\",\"WEST\",\"WEST\",\"WEST\",\"WEST\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "                \n",
    "\n",
    "x = a['string1'].str.split(' ', expand=True).rename(columns = lambda x: \"string\"+str(x+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Converted columns to strings inorder to replace \"None\" with \" \"\n",
    "\n",
    "a['string1']= a['string1'].astype(str)\n",
    "a['string2']= a['string2'].astype(str)\n",
    "a['string3']= a['string3'].astype(str)\n",
    "a['string4']= a['string4'].astype(str)\n",
    "a['string5']= a['string5'].astype(str)\n",
    "\n",
    "\n",
    "p = a.replace(['None'],[' '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Remove \"-\" from the Street Number as above in inspection data se\n",
    " \n",
    "x = a['string1'].str.split('-', expand=True).rename(columns = lambda x: \"string\"+str(x+1))\n",
    "\n",
    "x['string2'] = x['string2'].astype(str)\n",
    "j = x.replace(['None'],[' '])\n",
    "\n",
    "j = j.applymap(lambda x: x.strip() if type(x)==str else x)\n",
    "\n",
    "j['Street_Number'] = j['string1'] + j['string2']\n",
    "\n",
    "p['string1'] = j['Street_Number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Concatenated split columns back to full street address\n",
    "\n",
    "p['Adj_New'] = p['string1'] + ' ' + p['string2'] + ' ' + p['string3'] + ' ' + p['string4'] + ' ' + p['string5']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "               # Add 'Final address to food df' \n",
    "\n",
    "food['Final_Street'] = p['Adj_New']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "               # concatenate 'Final Street' with 'Borough' to create unique key to join tables\n",
    "\n",
    "food['Address_Id'] = food['Borough'] + \" | \" + food['Final_Street']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Create new 'Weekday' column form date for weekday analysis\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "import calendar\n",
    "\n",
    "y = food['Incident_Date']                                     # Define variables for loop    \n",
    "x = []                                                        \n",
    "\n",
    "for i in y:                                                    # Take out double white spaces\n",
    "        x.append(calendar.day_name[i.weekday()])                            \n",
    "    \n",
    "y = pd.Series(x)                                               # Add new 'Adjusted Street' column to df\n",
    "food.insert(loc=0, column='Weekday', value=y)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Re-order columns\n",
    "\n",
    "food = food[[\"id\",\"Address_Id\",\"Incident_Date\",\"Weekday\",\"Complaint\",\n",
    "             \"Final_Street\",\"Borough\",\"Zip\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Set 'id' as index\n",
    "\n",
    "food.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # final strip of trailing white space\n",
    "\n",
    "food = food.applymap(lambda x: x.strip() if type(x)==str else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # delet 'N/A' rows\n",
    "\n",
    "food = food[food.Zip != 'N/A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Save Transforme DataFrame to csv file\n",
    "\n",
    "food.to_csv('c:/LearnPython/final_food.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataFrames into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "                # Create Engine and Pass in MySQL Connection\n",
    "\n",
    "connection_string = \"root:toor@localhost/NewYorkCity_db\"\n",
    "engine = create_engine(f'mysql://{connection_string}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Confirm tables set up in MySql\n",
    "    \n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Load data into database tables after first deleting data in tables in mysql\n",
    "\n",
    "food.to_sql(name='food', con=engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "                # Verify load successful\n",
    "\n",
    "pd.read_sql_query('select * from food', con=engine).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                # Load data into database tables after first deleting data in tables in mysql\n",
    "\n",
    "inspections.to_sql(name='inspection', con=engine, if_exists='append', index=True, chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "                # Verify load successful\n",
    "\n",
    "pd.read_sql_query('select * from inspection', con=engine).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
